{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c42e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "987/987 [==============================] - 3s 2ms/step - loss: 11017.0752 - val_loss: 5516.4146\n",
      "Epoch 2/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 6010.0620 - val_loss: 4347.8159\n",
      "Epoch 3/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 5053.2524 - val_loss: 4188.2920\n",
      "Epoch 4/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 4599.1680 - val_loss: 4130.8022\n",
      "Epoch 5/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 4275.4209 - val_loss: 3567.8828\n",
      "Epoch 6/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3883.7441 - val_loss: 3164.5945\n",
      "Epoch 7/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3685.1284 - val_loss: 2726.9487\n",
      "Epoch 8/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3277.1475 - val_loss: 2595.6384\n",
      "Epoch 9/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3021.2678 - val_loss: 2568.4783\n",
      "Epoch 10/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2779.6909 - val_loss: 2299.1143\n",
      "Epoch 11/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2685.6521 - val_loss: 1995.9608\n",
      "Epoch 12/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2468.9617 - val_loss: 1796.4994\n",
      "Epoch 13/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2433.9082 - val_loss: 1890.3053\n",
      "Epoch 14/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2296.1880 - val_loss: 2054.2146\n",
      "Epoch 15/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2330.2866 - val_loss: 1836.1487\n",
      "Epoch 16/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2204.1062 - val_loss: 1541.2911\n",
      "Epoch 17/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2162.8711 - val_loss: 1795.7122\n",
      "Epoch 18/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2131.0566 - val_loss: 1560.8716\n",
      "Epoch 19/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2061.0186 - val_loss: 1630.2104\n",
      "Epoch 20/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2043.1487 - val_loss: 1506.9988\n",
      "Epoch 21/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2037.0852 - val_loss: 1516.5668\n",
      "Epoch 22/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2010.7650 - val_loss: 1416.9082\n",
      "Epoch 23/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2015.8837 - val_loss: 1418.9911\n",
      "Epoch 24/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1919.5033 - val_loss: 1538.6835\n",
      "Epoch 25/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1938.3093 - val_loss: 1406.6415\n",
      "Epoch 26/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1915.9973 - val_loss: 1516.4231\n",
      "Epoch 27/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1935.8458 - val_loss: 1483.5739\n",
      "Epoch 28/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1916.3160 - val_loss: 1449.7838\n",
      "Epoch 29/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1882.5681 - val_loss: 1546.3257\n",
      "Epoch 30/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1884.0048 - val_loss: 1712.4103\n",
      "309/309 [==============================] - 0s 979us/step - loss: 1099.5321\n",
      "Epoch 1/50\n",
      "987/987 [==============================] - 3s 2ms/step - loss: 13963.7803 - val_loss: 5767.4775\n",
      "Epoch 2/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 5046.8105 - val_loss: 3554.8699\n",
      "Epoch 3/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 4313.5835 - val_loss: 3284.2878\n",
      "Epoch 4/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3898.5342 - val_loss: 3282.9204\n",
      "Epoch 5/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3604.8542 - val_loss: 2810.3105\n",
      "Epoch 6/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3402.3000 - val_loss: 2885.1455\n",
      "Epoch 7/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3229.1123 - val_loss: 2621.8940\n",
      "Epoch 8/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3068.3330 - val_loss: 3961.7493\n",
      "Epoch 9/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 3016.5134 - val_loss: 2311.7329\n",
      "Epoch 10/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2872.5159 - val_loss: 2418.5637\n",
      "Epoch 11/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2753.9041 - val_loss: 2158.2427\n",
      "Epoch 12/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2746.3179 - val_loss: 2057.0876\n",
      "Epoch 13/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2626.3926 - val_loss: 2459.7944\n",
      "Epoch 14/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2601.6619 - val_loss: 2025.2312\n",
      "Epoch 15/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2544.9639 - val_loss: 2295.1758\n",
      "Epoch 16/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2497.9705 - val_loss: 1880.7177\n",
      "Epoch 17/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2512.9680 - val_loss: 1827.4106\n",
      "Epoch 18/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2413.6082 - val_loss: 1920.8630\n",
      "Epoch 19/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2375.1553 - val_loss: 2165.7070\n",
      "Epoch 20/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2359.3911 - val_loss: 1840.6815\n",
      "Epoch 21/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2331.6113 - val_loss: 1720.8146\n",
      "Epoch 22/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2286.7932 - val_loss: 1717.7037\n",
      "Epoch 23/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2282.7959 - val_loss: 1997.6162\n",
      "Epoch 24/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2267.0798 - val_loss: 1696.9368\n",
      "Epoch 25/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2217.7629 - val_loss: 1676.7717\n",
      "Epoch 26/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2217.0552 - val_loss: 1712.2638\n",
      "Epoch 27/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2210.7214 - val_loss: 1727.2118\n",
      "Epoch 28/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2160.6318 - val_loss: 1657.7855\n",
      "Epoch 29/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2170.5007 - val_loss: 1705.6670\n",
      "Epoch 30/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2148.4214 - val_loss: 1572.0367\n",
      "Epoch 31/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2152.2268 - val_loss: 1596.3446\n",
      "Epoch 32/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2110.4814 - val_loss: 1538.9745\n",
      "Epoch 33/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2128.2908 - val_loss: 1571.1390\n",
      "Epoch 34/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2140.2402 - val_loss: 1532.2858\n",
      "Epoch 35/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2085.9104 - val_loss: 1705.0277\n",
      "Epoch 36/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2099.4270 - val_loss: 1576.8987\n",
      "Epoch 37/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2097.1116 - val_loss: 1524.5455\n",
      "Epoch 38/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2094.6147 - val_loss: 1509.3337\n",
      "Epoch 39/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2051.3523 - val_loss: 1487.2692\n",
      "Epoch 40/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2060.6738 - val_loss: 1510.9259\n",
      "Epoch 41/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2056.2754 - val_loss: 1483.6240\n",
      "Epoch 42/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2020.8687 - val_loss: 1650.7039\n",
      "Epoch 43/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2033.2748 - val_loss: 1479.5049\n",
      "Epoch 44/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2055.2500 - val_loss: 1494.6741\n",
      "Epoch 45/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 2004.6010 - val_loss: 1605.7828\n",
      "Epoch 46/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1982.6813 - val_loss: 1462.9071\n",
      "Epoch 47/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1976.4731 - val_loss: 1419.1069\n",
      "Epoch 48/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1981.2070 - val_loss: 1444.9723\n",
      "Epoch 49/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1964.2159 - val_loss: 1467.1541\n",
      "Epoch 50/50\n",
      "987/987 [==============================] - 2s 2ms/step - loss: 1947.1172 - val_loss: 1427.4430\n",
      "309/309 [==============================] - 0s 903us/step - loss: 1146.7677\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Step 1: Load and preprocess the dataset\n",
    "df = pd.read_csv(r'D:\\Y\\DATA\\PREPROCESS\\BookA.csv', parse_dates=['Date'], index_col=['Date'])\n",
    "\n",
    "# Step 2: Split the data into train and test sets\n",
    "features = df[['PM2.5', 'PM10', 'NO', 'NO2', 'SO2', 'CO', 'Ozone', 'RH', 'WS', 'WD', 'SR']].values\n",
    "targets = df[['PM2.5']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Step 3: Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Reshape the data for LSTM input\n",
    "time_steps = 10\n",
    "num_features = features.shape[1]\n",
    "\n",
    "def reshape_data(X, y, time_steps):\n",
    "    X_reshaped = []\n",
    "    y_reshaped = []\n",
    "    for i in range(time_steps, len(X)):\n",
    "        X_reshaped.append(X[i - time_steps:i, :])\n",
    "        y_reshaped.append(y[i])\n",
    "    return np.array(X_reshaped), np.array(y_reshaped)\n",
    "\n",
    "X_train_reshaped, y_train_reshaped = reshape_data(X_train, y_train, time_steps)\n",
    "X_test_reshaped, y_test_reshaped = reshape_data(X_test, y_test, time_steps)\n",
    "\n",
    "# Step 5: Define the fitness function for PSO optimization\n",
    "def fitness_function(position):\n",
    "    num_lstm_units = int(position[0])\n",
    "    learning_rate = position[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_lstm_units, activation='relu', input_shape=(time_steps, num_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train_reshaped, y_train_reshaped, epochs=50, batch_size=32,\n",
    "                        validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    loss = model.evaluate(X_test_reshaped, y_test_reshaped)\n",
    "    return loss\n",
    "\n",
    "# Step 6: Implement Particle Swarm Optimization\n",
    "class Particle:\n",
    "    def __init__(self, position, velocity):\n",
    "        self.position = position\n",
    "        self.velocity = velocity\n",
    "        self.best_position = position\n",
    "        self.best_fitness = float('inf')\n",
    "\n",
    "class PSO:\n",
    "    def __init__(self, num_particles, num_dimensions, bounds, max_iterations):\n",
    "        self.num_particles = num_particles\n",
    "        self.num_dimensions = num_dimensions\n",
    "        self.bounds = bounds\n",
    "        self.max_iterations = max_iterations\n",
    "        self.global_best_position = None\n",
    "        self.global_best_fitness = float('inf')\n",
    "        self.particles = []\n",
    "\n",
    "    def initialize_particles(self):\n",
    "        for _ in range(self.num_particles):\n",
    "            position = np.random.uniform(self.bounds[0], self.bounds[1], self.num_dimensions)\n",
    "            velocity = np.zeros(self.num_dimensions)\n",
    "            particle = Particle(position, velocity)\n",
    "            self.particles.append(particle)\n",
    "\n",
    "    def update_particle_velocity(self, particle):\n",
    "        inertia_weight = 0.5\n",
    "        cognitive_weight = 1.0\n",
    "        social_weight = 1.0\n",
    "\n",
    "        r1 = np.random.rand(self.num_dimensions)\n",
    "        r2 = np.random.rand(self.num_dimensions)\n",
    "\n",
    "        cognitive_component = cognitive_weight * r1 * (particle.best_position - particle.position)\n",
    "        social_component = social_weight * r2 * (self.global_best_position - particle.position)\n",
    "        particle.velocity = inertia_weight * particle.velocity + cognitive_component + social_component\n",
    "\n",
    "    def update_particle_position(self, particle):\n",
    "        particle.position += particle.velocity\n",
    "        particle.position = np.clip(particle.position, self.bounds[0], self.bounds[1])\n",
    "\n",
    "    def evaluate_fitness(self, particle):\n",
    "        fitness = fitness_function(particle.position)\n",
    "        return fitness\n",
    "\n",
    "    def update_global_best(self):\n",
    "        for particle in self.particles:\n",
    "            if particle.best_fitness < self.global_best_fitness:\n",
    "                self.global_best_fitness = particle.best_fitness\n",
    "                self.global_best_position = particle.best_position\n",
    "\n",
    "    def run(self):\n",
    "        self.initialize_particles()\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            for particle in self.particles:\n",
    "                fitness = self.evaluate_fitness(particle)\n",
    "\n",
    "                if fitness < particle.best_fitness:\n",
    "                    particle.best_fitness = fitness\n",
    "                    particle.best_position = particle.position\n",
    "\n",
    "                if fitness < self.global_best_fitness:\n",
    "                    self.global_best_fitness = fitness\n",
    "                    self.global_best_position = particle.position\n",
    "\n",
    "                self.update_particle_velocity(particle)\n",
    "                self.update_particle_position(particle)\n",
    "\n",
    "            self.update_global_best()\n",
    "\n",
    "            print(\"Iteration:\", iteration + 1, \"Best Fitness:\", self.global_best_fitness)\n",
    "\n",
    "        print(\"Optimization finished!\")\n",
    "        print(\"Best Fitness:\", self.global_best_fitness)\n",
    "        print(\"Best Position:\", self.global_best_position)\n",
    "\n",
    "# Step 7: Run the hybrid model using PSO and LSTM\n",
    "num_particles = 20\n",
    "num_dimensions = 2\n",
    "bounds = [(16, 128), (0.001, 0.1)]\n",
    "#bounds = [(16), (0.001)]\n",
    "max_iterations = 50\n",
    "\n",
    "pso = PSO(num_particles, num_dimensions, bounds, max_iterations)\n",
    "pso.run()\n",
    "\n",
    "# Step 8: Evaluate the final LSTM model with the optimized hyperparameters\n",
    "best_position = pso.global_best_position\n",
    "\n",
    "num_lstm_units = int(best_position[0])\n",
    "learning_rate = best_position[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(num_lstm_units, activation='relu', input_shape=(time_steps, num_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train_reshaped, y_train_reshaped, epochs=50, batch_size=32,\n",
    "                    validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "loss = model.evaluate(X_test_reshaped, y_test_reshaped)\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "\n",
    "# Step 9: Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58a8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7d015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
