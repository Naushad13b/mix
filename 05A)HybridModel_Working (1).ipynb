{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515deff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from darts.datasets import AirPassengersDataset\n",
    "from darts import TimeSeries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399cd625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>228.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>222.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01</th>\n",
       "      <td>128.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>68.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-01</th>\n",
       "      <td>62.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PM2.5\n",
       "Date              \n",
       "2021-01-01  228.53\n",
       "2021-02-01  222.37\n",
       "2021-03-01  128.14\n",
       "2021-04-01   68.44\n",
       "2021-05-01   62.51"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data using datetime and set index to datetime\n",
    "df = pd.read_csv(r'C:\\Users\\91783\\Desktop\\DataSet\\1_Bhiwadi\\Book_1_PM.csv',\n",
    "                                parse_dates=['Date'],\n",
    "                                index_col=['Date'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35eb77e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2matrix(data_arr, look_back):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data_arr)-look_back):\n",
    "        d=i+look_back  \n",
    "        X.append(data_arr[i:d,])\n",
    "        Y.append(data_arr[d,])\n",
    "        return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c934fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data set into testing dataset and train dataset\n",
    "train_size = 300\n",
    "train, test =df.values[0:train_size,:],df.values[train_size:len(df.values),:]\n",
    "# setup look_back window \n",
    "look_back = 30\n",
    "#convert dataset into right shape in order to input into the DNN\n",
    "trainX, trainY = convert2matrix(train, look_back)\n",
    "testX, testY = convert2matrix(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b06ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "def model_dnn(look_back):\n",
    "    model_1=Sequential()\n",
    "    model_1.add(Dense(units=32, input_dim=look_back, activation='relu'))\n",
    "    model_1.add(Dense(8, activation='relu'))\n",
    "    model_1.add(Dense(1))\n",
    "    model_1.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e765bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=model_dnn(look_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model_1.fit(trainX,trainY, epochs=15, batch_size=8, verbose=2, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n",
    "#Taking predictions\n",
    "Y_pred1 = model_1.predict(testX)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(testY, Y_pred1)\n",
    "\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking predictions\n",
    "Y_pred1 = model_1.predict(testX)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(testY, Y_pred1)\n",
    "\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ceadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "def model_rnn(look_back):\n",
    "    model_2=Sequential()\n",
    "    model_2.add(SimpleRNN(units=32, input_shape=(1,look_back), activation=\"relu\"))\n",
    "    model_2.add(Dense(8, activation='relu'))\n",
    "    model_2.add(Dense(1))\n",
    "    model_2.compile(loss='mean_squared_error',  optimizer='adam',metrics = ['mse', 'mae'])\n",
    "    return model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2=model_rnn(look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ca0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2=model_2.fit(trainX,trainY, epochs=15, batch_size=8, verbose=2, validation_data=(testX,testY),callbacks=[EarlyStopping(monitor='val_loss', patience=10)],shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking predictions\n",
    "Y_pred2 = model_2.predict(testX)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(testY, Y_pred2)\n",
    "\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "values = df.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_dataset = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707294f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dataset[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eb870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a window for previous data\n",
    "def to_supervised(train):\n",
    "    window_size = 4\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(window_size, len(train)):\n",
    "        X.append(train[i-window_size:i,:])\n",
    "        Y.append(train[i,0:1])\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = to_supervised(scaled_dataset)\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print('Y' ,Y.shape)\n",
    "print('X' ,X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "n_train = 3*30\n",
    "X_train, X_test = X[n_train:,] , X[:n_train,]\n",
    "print('X_train' ,X_train.shape)\n",
    "print('X_test' ,X_test.shape)\n",
    "\n",
    "Y_train, Y_test = Y[n_train:,] , Y[:n_train,]\n",
    "print('Y_train' ,Y_train.shape)\n",
    "print('Y_test' ,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing LSTM model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=50,\n",
    "                    batch_size=8, validation_data=(X_test, Y_test),\n",
    "                    verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ebdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking predictions\n",
    "Y_pred_3 = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(Y_test, Y_pred_3)\n",
    "\n",
    "print(mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973df043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the split point index to keep 1 month (30 days) data as test set\n",
    "n_test = 61\n",
    "train_data = df.iloc[:len(df) - n_test]\n",
    "test_data = df.iloc[len(df) - n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df56e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
    "                        FutureWarning)\n",
    "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
    "                        FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA,ARIMAResults\n",
    "model = ARIMA(train_data['PM2.5'],order=(1,2,3))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predicted values on the test set\n",
    "start = len(train_data)\n",
    "end = len(train_data) + len(test_data) - 1\n",
    "predictions = results.predict(start=start,end=end,dynamic=True,typ='levels').rename('ARIMA Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to expected values\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"predicted = {predictions[i]}, expected = {test_data['PM2.5'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff942610",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(columns=['Actual','Predicted'])\n",
    "compare['Actual'] = test_data['PM2.5']\n",
    "compare['Predicted'] = predictions\n",
    "compare.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09caa3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=test_data['PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83eb949",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3=d.append([d1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8470f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4=pd.DataFrame(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b309cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5605f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a1d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
